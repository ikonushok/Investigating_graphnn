{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GDL100-Practical1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#GDL100 Practical 1: Geometric Deep Learning 2022\n"
      ],
      "metadata": {
        "id": "ZCi6jrvs4DOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welcome to practical 1 of the AMMI course on geometric deep learning. We have seen the equations and theory of graph representation learning in the lectures, so the aim of this practical is to further consolidate this in code. \n",
        "\n",
        "Through the practical we will look at:\n",
        "- Reviewing notation for graphs and looking at the differences in node/edge level learning tasks and graph-level learning tasks.\n",
        "- Taking a tour from implementing and applying feed forward MLPs to implementing a convolutional graph layer exploring semi-supervised node prediction.\n",
        "- Moving to graph-level prediction and the challenges of batching observations that are graphs.\n",
        "- Studying the expressive power of GNNs on different graphs. \n",
        "\n",
        "Doing so we will also familiarise ourselves with the various challenges involved in implementing GNNs, the various graph learning tasks and working with graph structured data.\n",
        "\n",
        "**Here are the authors**: Please contact us for any questions regarding the notebook. \\\\\n",
        "\n",
        "* Cristian Bodnar (cb2015@cam.ac.uk) \\\\\n",
        "* Iulia Duta (id366@cam.ac.uk) \\\\\n",
        "* Paul Scherer (pms69@cam.ac.uk)\n",
        "\n",
        "\\\\"
      ],
      "metadata": {
        "id": "rcHQFzsOFwPx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "qU87TNON39IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Install required libraries\n",
        "\n",
        "!pip install networkx\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install mycolorpy\n",
        "!pip install colorama"
      ],
      "metadata": {
        "id": "gaw6Hh5o5nrs",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Import modules\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import math\n",
        "import itertools\n",
        "import scipy as sp\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch_geometric\n",
        "from torch_geometric.datasets import Planetoid, ZINC, GNNBenchmarkDataset\n",
        "from torch_scatter import scatter_mean, scatter_max, scatter_sum\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "from torch.nn import Embedding\n",
        "\n",
        "import pdb\n",
        "\n",
        "#for nice visualisations\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "import colorama\n",
        "\n",
        "import scipy.linalg\n",
        "from scipy.linalg import block_diag"
      ],
      "metadata": {
        "id": "ZLrrWpkk6xv-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Helper functions for plots and visualisations\n",
        "\n",
        "####### VISUALISATIONS #######\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "      \n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery \n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" \n",
        "  This function is a basic, non-bijective one for visualising the embedings. \n",
        "  Please use it for guidance, not as a mathematical proof in Part 3.\n",
        "  It is used just for educational/visualisation purpose.\n",
        "  You are free to change it with whatever suits you best.\n",
        "  Hash the tensor representing nodes' features \n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes) \n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb++0.00001)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "####### PLOTS #######\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "    \n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "  "
      ],
      "metadata": {
        "id": "EiuxXrwgmBE-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries on graphs and notation\n",
        "\n",
        "As described in the lectures a graph is mathematical structure which defines a set of entities which are related in some way. Graphs contain *nodes* or *vertices* representing said entities with related nodes being connected by an *edge* or *link* that records the relation. \n",
        "\n",
        "Mathematically we can define simple graph as an ordered tuple $\\mathcal{G} = (V, E)$ where $V$ is a set of nodes (or vertices) and $E \\subseteq (V \\times V$) is a 2-tuple set of the edges in the graph. Hence if $u$ and $v$ are nodes in $\\mathcal{G}$, their relation is recorded with edge as $(u,v) \\in E$ if the edge is directed from $u$ to $v$. The neighbours of a node $u$ is the set of nodes which share an edge with $u$, denoted $\\mathcal{N}(u) = \\{v | (u, v) \\in E\\}$. \n",
        "\n",
        "Edges can be directed or undirected. Directed edges are uni-directional relations from a source node $u$ and target node $v$ recorded as $(u,v) \\in E$ and importantly $(u,v) \\neq (v,u)$. Undirected edges are bi-directional and hence $(u,v) == (v,u)$. \n",
        "\n",
        "Graphs can be represented nicely by matrices. For a graph with $n$ nodes, $A \\in \\mathbb{R}^{n \\times n}$ is a symmetric adjacency matrix where is $a_{i,j}$ is the weight of the edge between nodes $v_i$ and $v_j$. If $(v_i, v_j) \\notin E$ then $a_{i,j} = 0$. A diagonal degree matrix $D \\in \\mathbb{R}^{n \\times n}$ is defined as the matrix where each entry on the diagonal is the row-sum of the adjacency matrix. Note that this gives us what we need to define the Laplacian matrix of the graph $L = D-A$. For graphs with node features, each node $v_i \\in V$ has an associated $d$-dimensional feature vector $\\mathbf{x_i} \\in \\mathbb{R}^{d}$. Then the feature matrix $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ can be used to represent the feature vectors for every node in the graph. Can you think of how edge feature matrix would be defined?"
      ],
      "metadata": {
        "id": "ClxVKxwvB41e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine learning on graph structured data with GNNs\n",
        "\n",
        "Machine learning tasks on graph structured data can be categorised based on the nuanced differences of the dataset and the task being studied. Most generally we are interested in the following tasks\n",
        "\n",
        "- **Node prediction:** a data observation is a node within a graph, we are interested in doing node classification/regression. Ex. Cora dataset where we are interested in categorising papers that are nodes of a larger citation network\n",
        "- **Edge prediction:** we are interested in predicting edges between samples in the dataset.\n",
        "- **Graph level prediction:** a data observation is a graph, i.e. our dataset consists of graphs and we are interested in graph classification/regression. Ex. ZINC dataset where we are interested in predicting the solubility of each molecule/graph in the dataset\n",
        "\n",
        "To motivate GNNs we will briefly look at the Cora dataset and node level learning. Following this we will look at graph level prediction as this will involve batching approaches that are likely different from what you are accustomed to."
      ],
      "metadata": {
        "id": "Arp-90joB6uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: A first look at Cora\n",
        "\n",
        "A now classic dataset for GNNs (one whose use is also discouraged within some circles as it is very easy to overfit on), Cora is a nice small dataset to start looking at GNNs. There are many variations of the Cora dataset originally presented in \"Automating the Construction of Internet Portals with Machine Learning\" by McCallum et al. (https://link.springer.com/article/10.1023/A:1009953814988). \n",
        "\n",
        "We will use the Cora dataset variant as presented in “FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling” (https://arxiv.org/abs/1801.10247). It describes a citation network of 2708 papers and our task is classify each paper into one of 7 different categories. Some quick facts of this Cora variant:\n",
        "\n",
        "\n",
        "*   There are 2708 papers (i.e. observations in the dataset)\n",
        "  * 1208 train\n",
        "  * 500 validation\n",
        "  * 1000 test\n",
        "*   Each paper is represented by a 1433 dimensional bag-of-words vector\n",
        "*   Each paper belongs to one of 7 classes\n",
        "\n",
        "Ignoring GNNs for a moment, our first attempt would be to use a simple model such as a feed forward MLP. In fact, it's always good practice to explore the task with simpler models for debugging and benchmarking. \n",
        "\n",
        "We will work with the cora dataset through a `CoraDataset` object which will download the dataset and provides the following methods:\n",
        "\n",
        "- `train_val_test_split(self)`: returns torch tensors for `train_x`, `train_y`, `validation_x`, `validation_y`, `test_x`, `test_y`, corresponding to input x and target y for each of the train/val/test splits.\n",
        "- `get_fullx(self)`: returns the feature matrix $\\mathbf{X} \\in \\mathbb{R}^{|V| \\times d}$ where $V$ is the set of nodes and $d$ the feature vector dimensionality.\n",
        "- `get_adjacency_matrix(self)`: As the name suggests, returns a dense adjacency matrix $\\mathbf{A}$"
      ],
      "metadata": {
        "id": "erI_trUhTvSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] `CoraDataset` implementation\n",
        "# Let's get the Planetoid Cora dataset from \n",
        "# “FastGCN: Fast Learning with Graph Convolutional \n",
        "# Networks via Importance Sampling” (https://arxiv.org/abs/1801.10247)\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "class CoraDataset(object):\n",
        "    def __init__(self):\n",
        "        super(CoraDataset, self).__init__()\n",
        "        cora_pyg = Planetoid(root='/tmp/Cora', name='Cora', split=\"full\")\n",
        "        self.cora_data = cora_pyg[0]\n",
        "        self.train_mask = self.cora_data.train_mask\n",
        "        self.valid_mask = self.cora_data.val_mask\n",
        "        self.test_mask = self.cora_data.test_mask\n",
        "\n",
        "    def train_val_test_split(self):\n",
        "        train_x = self.cora_data.x[self.cora_data.train_mask]\n",
        "        train_y = self.cora_data.y[self.cora_data.train_mask]\n",
        "\n",
        "        valid_x = self.cora_data.x[self.cora_data.val_mask]\n",
        "        valid_y = self.cora_data.y[self.cora_data.val_mask]\n",
        "\n",
        "        test_x = self.cora_data.x[self.cora_data.test_mask]\n",
        "        test_y = self.cora_data.y[self.cora_data.test_mask]\n",
        "        return train_x, train_y, valid_x, valid_y, test_x, test_y\n",
        "\n",
        "    def get_fullx(self):\n",
        "        return self.cora_data.x\n",
        "\n",
        "    def get_adjacency_matrix(self):\n",
        "        # We will ignore this for the first part\n",
        "        adj = to_dense_adj(self.cora_data.edge_index)[0]\n",
        "        return adj"
      ],
      "metadata": {
        "id": "OxvbRR52iKEf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets download our cora dataset and get the splits\n",
        "cora_data = CoraDataset()\n",
        "train_x, train_y, valid_x, valid_y, test_x, test_y = cora_data.train_val_test_split()\n",
        "\n",
        "# Always check and confirm our data shapes match our expectations\n",
        "print(f\"Train shape x: {train_x.shape}, y: {train_y.shape}\")\n",
        "print(f\"Val shape x: {valid_x.shape}, y: {valid_y.shape}\")\n",
        "print(f\"Test shape x: {test_x.shape}, y: {test_y.shape}\")"
      ],
      "metadata": {
        "id": "q_7BEhQJt6AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Hyperparameters MLP\n",
        "\n",
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ],
      "metadata": {
        "id": "h1fue_eNL4Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets implement a simple feed forward MLP\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleMLP(nn.Module):\n",
        "    \"\"\"A simple feed forward neural network with no hidden layers\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimpleMLP, self).__init__()\n",
        "        self.layer_1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        # y_hat = F.log_softmax(x, dim=1) <- old version\n",
        "        y_hat = x\n",
        "        return y_hat"
      ],
      "metadata": {
        "id": "sFigi0DQT3zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets define some utility functions for training and computing performance metrics\n",
        "# and then see how our model does!\n",
        "def train_mlp_cora(x, y, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    y_hat = model(x)\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "def evaluate_mlp_cora(x, y, model):\n",
        "    model.eval()\n",
        "    y_hat = model(x)\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "    return accuracy\n",
        "\n",
        "def train_eval_loop(model, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
        "    optimiser = optim.Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_mlp_cora(train_x, train_y, model, optimiser)\n",
        "        train_acc = evaluate_mlp_cora(train_x, train_y, model)\n",
        "        valid_acc = evaluate_mlp_cora(valid_x, valid_y, model)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f}\",\n",
        "                    f\"validation accuracy: {valid_acc:.3f}\")\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    # Lets look at our final test performance\n",
        "    test_acc = evaluate_mlp_cora(test_x, test_y, model)\n",
        "    print(f\"Our final test accuracy for the SimpleMLP is: {test_acc:.3f}\")\n",
        "    return training_stats"
      ],
      "metadata": {
        "id": "IXoEefwAEbeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our model \n",
        "model = SimpleMLP(input_dim=train_x.shape[-1], output_dim=7)\n",
        "\n",
        "# Run training loop\n",
        "train_stats_mlp_cora = train_eval_loop(model, train_x, train_y, valid_x, valid_y, test_x, test_y)\n",
        "plot_stats(train_stats_mlp_cora, name=\"MLP_Cora\")"
      ],
      "metadata": {
        "id": "_olnWUkaLRtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should be getting final test accuracies of around 65% on Cora for an extremely simple MLP model. Not too bad!\n",
        "\n",
        "But are we using all the information/data available to us and can we do better with it?\n",
        "\n",
        "# Our first GNN layer\n",
        "\n",
        "On our application of the MLP on Cora we have completely ignored the fact that Cora is a citation *network*! In Cora citations form undirected edges between each of the nodes (papers) in this network. We think this additional information can be useful for categorising our papers, but how can we incorporate this structure in a neural network layer? \n",
        "\n",
        "In lectures 3-4 we were introduced to a general blue-print for creating GNN layers. We can build GNN layers $\\mathbf{F(X,A)}$ on graphs via the shared application of local permutation invariant $\\phi(\\mathbf{x_i}, \\mathbf{X}_{\\mathcal{N}_i})$. The various implementations of $\\phi$ is the subject of much research, for our purpose we will start by considering GNN layers with constant values for the convolution coefficients. \n",
        "\n"
      ],
      "metadata": {
        "id": "ngIihap9B_mx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generic GNN Layer of the \"convolutional\" flavour. We are interested in developing a layer that uses set parameters for $c_{i,j}, (i,j) \\in E$\n",
        "\n",
        "![convolutional.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ten8Yb-oubOh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Generic equation for convolutional GNN:\n",
        "$$\n",
        "\\mathbf{h_i} = \\phi \\big(\\mathbf{x_i}, \\oplus_{j \\in \\mathcal{N}_i} c_{i,j} \\psi (\\mathbf{x_j}) \\big)\n",
        "$$\n",
        "\n",
        "Getting more specific, let us look at the GCN from Kipf and Welling's \"Semi-Supervised Classification with Graph Convolutional Networks\" (https://arxiv.org/abs/1609.02907). This employs a symmetric normalisation for the convolution coefficients with a re-normalisation to tackle exploding parameters.\n",
        "\n",
        "$$\n",
        "\\mathbf{H} = \\sigma \\big( \\mathbf{\\tilde{D}}^{-\\frac{1}{2}} \\mathbf{\\tilde{A}} \\mathbf{\\tilde{D}}^{-\\frac{1}{2}} \\mathbf{X} \\mathbf{W} \\big)\n",
        "$$\n",
        "\n",
        "Where $\\mathbf{\\tilde{A}} = \\mathbf{A} + \\mathbf{I}$ and $\\mathbf{\\tilde{D}}$ is the degree matrix of $\\mathbf{\\tilde{A}}$.\n",
        "\n",
        "### 💻**Task 1.1**  Define $c_{i,j}$, $\\oplus_{j \\in \\mathcal{N}_i}$ and $\\phi$ _mathematically_ so that the behaviour of the generic, convolutional GNN layer is the same as a GCN. (0.5 Marks)\n"
      ],
      "metadata": {
        "id": "2EDBXcFuvWqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your answer here\n",
        "\n"
      ],
      "metadata": {
        "id": "aVks08i_U58B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 1.2** Implement the GCNLayer given the above equation. (1.0 Mark)"
      ],
      "metadata": {
        "id": "vOwxWgomU3kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Hyperparameters GNN\n",
        "\n",
        "NUM_EPOCHS =  100 #@param {type:\"integer\"}\n",
        "LR         = 0.01 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ],
      "metadata": {
        "id": "-BLISzysQkdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in initialisation and forward method the GCNLayer below\n",
        "class GCNLayer(nn.Module):\n",
        "    \"\"\"GCN layer to be implemented by students of practical\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # Compute symmetric norm\n",
        "        # self.adj_norm = ...\n",
        "\n",
        "        # + Simple linear transformation and non-linear activation\n",
        "        # self.linear = ...\n",
        "        # =========================================\n",
        "\n",
        "    def forward(self, x):\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # x = ...\n",
        "        # =========================================\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "fAfm307zEzBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semi-supervised learning: Transductive vs Inductive \n",
        "\n",
        "Notice that we use the entire adjacency and node feature matrix each time we call the GCNLayer as opposed to the specific subsets of the train/validation/test we did earlier with the MLP. This is because nodes from the different splits share edges with those from the other splits and building our representation requires these. Hence, the learning performed with our GCNLayer is an instance of *transductive semi-supervised learning* as the model gets to see all of the observations in the dataset. This is different to the *inductive* learning performed on the MLP where the model only sees the train observations during training and only sees validation/test observations for prediction. **Hint for one of the tasks** It is important to note that despite the model using all of the observations and entire adjacency matrix it does not use all of the targets!\n",
        "\n",
        "### 💻**Task 1.3** Look at the code below and the usage of the various `<split>_mask`s. What are they doing to the outputs of the GCNLayer, and why are they important? (0.5 Marks)"
      ],
      "metadata": {
        "id": "rJTiyZYs3cnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give your answer here\n"
      ],
      "metadata": {
        "id": "0lRUrIbjJMpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see the GCNLayer in action!\n",
        "class SimpleGNN(nn.Module):\n",
        "    \"\"\"Simple GNN model using the GCNLayer implemented by students\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        A (torch.Tensor): 2-D adjacency matrix\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, A):\n",
        "        super(SimpleGNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.A = A\n",
        "        self.gcn_layer = GCNLayer(input_dim, output_dim, A)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gcn_layer(x)\n",
        "        # y_hat = F.log_softmax(x, dim=1) <- old version\n",
        "        y_hat = x\n",
        "        return y_hat\n",
        "\n",
        "def train_gnn_cora(X, y, mask, model, optimiser):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    y_hat = model(X)[mask]\n",
        "    loss = F.cross_entropy(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "    return loss.data\n",
        "\n",
        "def evaluate_gnn_cora(X, y, mask, model):\n",
        "    model.eval()\n",
        "    y_hat = model(X)[mask]\n",
        "    y_hat = y_hat.data.max(1)[1]\n",
        "    num_correct = y_hat.eq(y.data).sum()\n",
        "    num_total = len(y)\n",
        "    accuracy = 100.0 * (num_correct/num_total)\n",
        "    return accuracy\n",
        "    \n",
        "# Training loop\n",
        "def train_eval_loop_gnn_cora(model, train_x, train_y, train_mask, \n",
        "                        valid_x, valid_y, valid_mask, \n",
        "                        test_x, test_y, test_mask\n",
        "                    ):\n",
        "    optimiser = optim.Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "    # Training loop\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        train_loss = train_gnn_cora(train_x, train_y, train_mask, model, optimiser)\n",
        "        train_acc = evaluate_gnn_cora(train_x, train_y, train_mask, model)\n",
        "        valid_acc = evaluate_gnn_cora(valid_x, valid_y, valid_mask, model)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} with train loss: {train_loss:.3f} train accuracy: {train_acc:.3f} validation accuracy: {valid_acc:.3f}\")\n",
        "        # store the loss and the accuracy for the final plot\n",
        "        epoch_stats = {'train_acc': train_acc, 'val_acc': valid_acc, 'epoch':epoch}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "    # Lets look at our final test performance\n",
        "    test_acc = evaluate_gnn_cora(test_x, test_y, test_mask, model)\n",
        "    print(f\"Our final test accuracy for the SimpleGNN is: {test_acc:.3f}\")\n",
        "    return training_stats"
      ],
      "metadata": {
        "id": "uJ_shXwaE4fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our model and optimiser\n",
        "A = cora_data.get_adjacency_matrix()\n",
        "X = cora_data.get_fullx()\n",
        "model = SimpleGNN(input_dim=train_x.shape[-1], output_dim=7, A=A)\n",
        "\n",
        "train_mask = cora_data.train_mask\n",
        "valid_mask = cora_data.valid_mask\n",
        "test_mask = cora_data.test_mask\n",
        "\n",
        "# Run training loop\n",
        "train_stats_gnn_cora = train_eval_loop_gnn_cora(model, X, train_y, train_mask, \n",
        "                                          X, valid_y, valid_mask, \n",
        "                                          X, test_y, test_mask\n",
        "                                       )\n",
        "plot_stats(train_stats_gnn_cora, name=\"GNN_Cora\")"
      ],
      "metadata": {
        "id": "Rl6KVverQy7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright we got quite the boost here, seeing final test performances of about 84% despite no change to the number of trainable parameters being used. Neat!"
      ],
      "metadata": {
        "id": "QA7iMu59vWyo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 1.4** In your own words describe why our GCNLayer outperforms the SimpleMLP despite having the same number of parameters? What are the positives and drawbacks? (0.5 Marks)"
      ],
      "metadata": {
        "id": "EqnjpDb6vXDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the answer here\n"
      ],
      "metadata": {
        "id": "KqgDQzYTFBki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 1.5** Explore enlargening the receptive field visible to the computation of $\\mathbf{H}$. First, how can this be done? Does this help? Try implementing this and observing the effect of increasing the receptive field of your GNN on performance.  (0.5 Marks)"
      ],
      "metadata": {
        "id": "pXgKhF0KFKhG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in the answer here\n"
      ],
      "metadata": {
        "id": "SgNujBdTVfYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try coding it out here!"
      ],
      "metadata": {
        "id": "Pf3l7oo6M3Nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 1.6** Considering why the GCNLayer improves the performance, what change can be made to the Cora network so that the GCNLayer would lose significant performance below the MLP. Implement this change and explain your work. (1.0 Marks)"
      ],
      "metadata": {
        "id": "udKGc_rBVj3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fill in your text answer here\n"
      ],
      "metadata": {
        "id": "ivuql2IeVrqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try coding it out here!"
      ],
      "metadata": {
        "id": "rDi76Q1XVpHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving on to graph level prediction\n",
        "Great you've covered the basics of GNN layer development and studying node level prediction.\n",
        "\n",
        "Now lets look at graph level prediction. Consider the differences: we are no longer looking at each observation being a node (typically represented by an associated feature vector) but now each observation is an entire graph! As we do so we run into our first challenge: how do we batch graphs that can come in different sizes?"
      ],
      "metadata": {
        "id": "74pk764NVvlQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Graph-level prediction"
      ],
      "metadata": {
        "id": "wv2w6Jy1Tm3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the previous section, you trained a Graph Neural Network for node-level prediction. Let's move to a graph-level task to understand **what changes you should make in the architecture** and **what are some limitations of classical models**. \n",
        "\n",
        "For this, we will use [ZINC](https://arxiv.org/abs/1610.02415). ZINC is a dataset for graph-regression. It contains about 12 000 molecular graphs with up to 38 nodes each and the task is to predict for each molecule the solubility (a scalar number).\n",
        "\n",
        "Let's load the dataset using the [torch_geometric.dataset](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.ZINC) and check what it contains:"
      ],
      "metadata": {
        "id": "Vaukihsc7CGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_zinc_dataset = ZINC(root='', split='train', subset=True)\n",
        "val_zinc_dataset = ZINC(root='', split='val', subset=True)\n",
        "test_zinc_dataset = ZINC(root='', split='test', subset=True)\n",
        "\n",
        "print(f\"\\nTrain examples: {len(train_zinc_dataset)}\")\n",
        "print(f\"Val examples: {len(val_zinc_dataset)}\")\n",
        "print(f\"Test examples: {len(test_zinc_dataset)}\\n\")\n",
        "\n",
        "one_graph = train_zinc_dataset[0]\n",
        "\n",
        "print(f\"First graph contains {one_graph.x.shape[0]} nodes, each characterised by {one_graph.x.shape[1]} features\")\n",
        "print(f\"Graph labels have shape: {one_graph.y.shape}\")\n"
      ],
      "metadata": {
        "id": "PIPvSUNiveCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To store information about each graph, we create the following ` Graph` class. Note that, instead of storing an entire adjacency matrix to describe the graph structure, we will store it more efficiently as a list of edges of shape `[2, num_edges]`.  \n",
        "\n",
        "Note: `*_zinc_dataset` loads above are not instances of Graph structure, but their structure [torch_geometric.Data](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) is a lot similar to that one.\n",
        "\n"
      ],
      "metadata": {
        "id": "RWLvgFErBlJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Graph(object):\n",
        "    def __init__(self, edge_index, x, y):\n",
        "        \"\"\" Graph structure \n",
        "            for a mini-batch it will store a big (sparse) graph \n",
        "            representing the entire batch\n",
        "        Args:\n",
        "            x: node features  [num_nodes x num_feats]\n",
        "            y: graph labels   [num_graphs]\n",
        "            edge_index: list of edges [2 x num_edges]\n",
        "        \"\"\"\n",
        "        self.edge_index = edge_index\n",
        "        self.x = x.to(torch.float32)\n",
        "        self.y = y\n",
        "        self.num_nodes = self.x.shape[0]\n",
        "\n",
        "    #ignore this for now, it will be useful for batching\n",
        "    def set_batch(self, batch):\n",
        "        \"\"\" list of ints that maps each node to the graph it belongs to\n",
        "            e.g. for batch = [0,0,0,1,1,1,1]: the first 3 nodes belong to graph_0 while\n",
        "            the last 4 belong to graph_1\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "\n",
        "    # this function return a sparse tensor\n",
        "    def get_adjacency_matrix(self):\n",
        "        \"\"\" from the list of edges create \n",
        "        a num_nodes x num_nodes sparse adjacency matrix\n",
        "        \"\"\"\n",
        "        return torch.sparse.LongTensor(self.edge_index, \n",
        "                              # we work with a binary adj containing 1 if an edge exist\n",
        "                              torch.ones((self.edge_index.shape[1])), \n",
        "                              torch.Size((self.num_nodes, self.num_nodes))\n",
        "                              )"
      ],
      "metadata": {
        "id": "yTnHMRJUueVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that, for efficiency, the adjacency matrix (`self.get_adjacency_matrix()`) is stored as a sparse matrix (using `torch.sparse.LongTensor()`). This means that, instead of the entire matrix, we will only store the indexes of the vertices and the value (weight) corresponding to each edge. This saves lots of memory in storing the tensors for which the majority of elements are zeros.\n",
        "\n",
        "If you need to convert a sparse tensor `x` into a dense one you can use `x.to_dense()`. Moreover, many operations are directly supported for sparse tensors via [torch.sparse](https://pytorch.org/docs/stable/sparse.html) (e.g. `torch.sparse.mm()` that multiplies a sparse matrix with a sparse/dense matrix)."
      ],
      "metadata": {
        "id": "_4T0NiLCN1E5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets visualize the graphs using the `networkx` library. \n",
        "\n",
        "*Showing how to do this is out of the scope of this lab, so the function is entirely coded for you, but you can find out more about this from [here](https://networkx.org/documentation/stable/tutorial.html).*"
      ],
      "metadata": {
        "id": "INzDD6nJEHR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gallery([one_graph], labels=np.array([one_graph.y]), max_fig_size=(8,10))"
      ],
      "metadata": {
        "id": "EO3ZDe1qEKqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mini-batching for graph data"
      ],
      "metadata": {
        "id": "h6DxbvCITrRj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are now dealing with multiple graphs, we need to figure out how to store them in mini-batches, to be able to make the computation as efficient as possible. For some types of data, stacking samples in mini-batches is a trivial task. For example, images of $32\\times32$ pixels are easy to batch because they have the same dimension (obtaining a tensor of dimension $batch\\_{size}\\times32\\times32$). On the other hand, graphs come in different sizes with adjacency matrices of different shapes:"
      ],
      "metadata": {
        "id": "H5QHpx1KMGLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'First graph : {train_zinc_dataset[0].x.shape} with adjacency {(train_zinc_dataset[0].num_nodes, train_zinc_dataset[0].num_nodes)}')\n",
        "print(f'Second graph: {train_zinc_dataset[1].x.shape} with adjacency {(train_zinc_dataset[1].num_nodes, train_zinc_dataset[1].num_nodes)}')\n",
        "print(f'Third graph : {train_zinc_dataset[2].x.shape} with adjacency {(train_zinc_dataset[2].num_nodes, train_zinc_dataset[2].num_nodes)}')\n"
      ],
      "metadata": {
        "id": "KgEw_0yeMyL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One solution for this is to create a single *sparse* graph as the union of all the graphs in the mini-batch as follow:\n",
        "\n",
        "1. stack the features $x$ for all the nodes in all the graphs\n",
        "2. stack the labels $y$ for all the nodes in all the graphs\n",
        "3. stack all the adjacency matrices $A_i$ as diagonal blocks in the new adjacency matrix\n",
        "\n",
        "This way, we will obtain a new graph containing $\\sum_{i=1}^{B}|V_i|$ nodes, where $B$ is the batch_size and by $|V_i|$ we denote the number of nodes in graph $i$. Note that since **no** edges connect nodes from different graphs,  the  information propagation will not be affected by the way we store it.  "
      ],
      "metadata": {
        "id": "rIpnDzA0OhVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1RwI0CYA57S0OgLxgHgV6PBFNG9tnGvGR\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ux65wTJLXCfJ4TI4Up4mCHkaSja8NgrJ\" width=\"500\">\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "ln-ifrAsLeSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the resulting matrix contains many zeros (sparse), thus our choice of storing the adjacency matrix as a sparse tensor can indeed bring us efficiency."
      ],
      "metadata": {
        "id": "vhaE6fTEPpKx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Until now, we have a way to store the graphs in a mini-batch such that they could be efficiently processed. \n",
        "\n",
        "However, we need to also be able to extract information from this structure, to recover the graphs that it contains. For this, we need to remember what initial graph each node belongs to.\n",
        "\n",
        "We will do this by storing a list of indices `(self.batch)`, which map each node in the batch-graph to the initial graph it belong to. For example `batch=[0,0,0,1,1,2,2,2]` indicates that first 3 nodes belong to $G_0$, the next 2 nodes belong to $G_1$ and the last 3 nodes belong to $G_2$.\n",
        "\n"
      ],
      "metadata": {
        "id": "SOrDII9ZRH1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻 **Task 2.1:** in the following you will have to implement the mini_batch function. (1.5 Marks)"
      ],
      "metadata": {
        "id": "W6S3ptlSMoGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mini_batch(graph_list: List[Graph]) -> Graph:\n",
        "    \"\"\" Built a sparse graph from a batch of graphs\n",
        "    Args:\n",
        "        graph_list: list of Graph objects in a batch\n",
        "    Returns:\n",
        "        a big (sparse) Graph representing the entire batch\n",
        "    \"\"\"\n",
        "    #insert first graph into the structure\n",
        "    batch_edge_index = graph_list[0].edge_index\n",
        "    batch_x = graph_list[0].x\n",
        "    batch_y = graph_list[0].y\n",
        "    batch_batch = torch.zeros((graph_list[0].num_nodes), dtype=torch.int64)\n",
        "    # ============ YOUR CODE HERE =============\n",
        "    # you may need additional variables\n",
        "    # ==========================================\n",
        "\n",
        "    #append the rest of the graphs to the structure\n",
        "    for idx, graph in enumerate(graph_list[1:]):\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # concat the features\n",
        "        # batch_x = ...\n",
        "        # concat the labels\n",
        "        # batch_y = ...\n",
        "\n",
        "        # concat the adjacency matrix as a block diagonal matrix\n",
        "        # batch_edge_index = ...\n",
        "        # ==========================================\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # create the array of indexes mapping nodes in the batch-graph\n",
        "        # to the graph they belong to\n",
        "        # specify the mapping between the new nodes and the graph they belong to (idx+1)\n",
        "        # batch_batch = ...\n",
        "        # ==========================================\n",
        "        pass\n",
        "    #create the big sparse graph \n",
        "    batch_graph = Graph(batch_edge_index, batch_x, batch_y)\n",
        "    #attach the index array to the Graph structure\n",
        "    batch_graph.set_batch(batch_batch)\n",
        "    return batch_graph"
      ],
      "metadata": {
        "id": "2cUts094jmZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize the mini-batching for a small list of batch_size=3 graphs.\n",
        "# Note that the three graphs viusalized are directed, \n",
        "# so the adjacency matrix will be non-symmetric \n",
        "# (even if the visualisation depicted them as undirected)\n",
        "\n",
        "# 3 random custom-designed graphs for visualisations\n",
        "graph1 = Graph(x=torch.rand((3,32)), \n",
        "               y=torch.rand((1)), \n",
        "               edge_index=torch.tensor([[0,0,0,1,1,1,2,2,2],[0,1,2,0,1,2,0,1,2]]))\n",
        "graph2 = Graph(x=torch.rand((5,32)), \n",
        "               y=torch.rand((1)), \n",
        "               edge_index=torch.tensor([[0,0,0,0,0,1,1,1,2,1,2,3,4], [0,1,2,3,4,2,3,4,4,0,0,0,0]]))\n",
        "graph3 = Graph(x=torch.rand((4,32)),\n",
        "               y=torch.rand((1)), \n",
        "              edge_index=torch.tensor([[0,1,2,3],[1,2,3,0]]))\n",
        "list_graphs = [graph1, graph2, graph3]\n",
        "\n",
        "# create a mini-batch from these 3 graphs\n",
        "batch_sample = create_mini_batch(list_graphs)\n",
        "\n",
        "# show statistics about the new graph built from this batch of graphs\n",
        "print(f\"Batch number_of_nodes: {batch_sample.num_nodes}\")\n",
        "print(f\"Batch features shape: {batch_sample.x.shape}\")\n",
        "print(f\"Batch labels shape: {batch_sample.y.shape}\")\n",
        "\n",
        "print(f\"Batch adjacency: \")\n",
        "print_color_numpy(batch_sample.get_adjacency_matrix().to_dense().numpy(), list_graphs)\n",
        "\n",
        "gallery([graph1, graph2, graph3, batch_sample], max_fig_size=(20,6), special_color=True)\n",
        "print(f\"And we also have access to which graph each node belongs to {batch_sample.batch}\\n\")\n"
      ],
      "metadata": {
        "id": "G6ZG23di3PRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scatter for aggregate information\n",
        "\n"
      ],
      "metadata": {
        "id": "d-s_ClR5Twrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you learned in the course, a simple way of aggregating information from node-level representation to obtain graph-level predictions is by (max/mean/sum) pooling. This can be efficiently obtained using the [`torch_scatter`](https://pytorch-scatter.readthedocs.io/en/1.3.0/functions/mean.html) library containing operations such as `scatter_mean`, `scatter_max`, `scatter_sum`.\n",
        "\n",
        " `scatter_*` receives as input a tensor and an array of indices and pools the information in the tensor stored at the indices specified in the array."
      ],
      "metadata": {
        "id": "9aFr-f5jlN-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation for `scatter_sum(array, index)`: \n",
        "\n",
        "\\\\\n",
        "\n",
        "<!-- <center> -->\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16E9Nyd-mPdYBWm923joWKJx4JR8c8pCz\" width=\"300\">\n",
        "<!-- </center> -->"
      ],
      "metadata": {
        "id": "3B9fsCGv0zil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻 **Task 2.2:** Having access to all the nodes embedings in a batch, use `scatter_*` to create a graph embedings for each graph in the batch (0.5 Marks)"
      ],
      "metadata": {
        "id": "drsR7k81mgbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = torch.tensor([13, 21, 3, 7, 11, 20, 2])\n",
        "index = torch.tensor([0,1,1,0,2,0,1])\n",
        "\n",
        "aggregate_sum = scatter_sum(array, index, dim=0)\n",
        "aggregate_mean = scatter_mean(array, index, dim=0)\n",
        "aggregate_max, aggregate_argmax = scatter_max(array, index, dim=0)\n",
        "\n",
        "print(\"Let's inspect what different scatter functions compute: \")\n",
        "print(f\"sum aggregation: {aggregate_sum}\")\n",
        "print(f\"mean aggregation: {aggregate_mean}\")\n",
        "print(f\"max aggregation: {aggregate_max}\\n\")\n",
        "\n",
        "batch_zinc = create_mini_batch(train_zinc_dataset[:3])\n",
        "# ============ YOUR CODE HERE =============\n",
        "# Given the nodes features for a batch of graphs (batch_zinc.x) \n",
        "# and the list of indices indicating what graph each node belongs to\n",
        "# apply scatter_* to obtain a graph embedings for each graph in the batch\n",
        "# You can play with all of them (scatter_mean/scatter_max/scatter_sum)\n",
        "\n",
        "# node_emb = ...\n",
        "# node_batch = ...\n",
        "# graph_emb = ...\n",
        "# ==========================================\n",
        "print(node_emb.shape)\n",
        "print(graph_emb.shape)\n"
      ],
      "metadata": {
        "id": "GuT1FhZH32jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ So until now we've learned \n",
        "1. how to store a batch of graphs in an efficient way\n",
        "2. how scatter operations work and how to use it to extract graph-level representations from node-level representations. \n",
        "\n",
        "Let's integrate what we've learned so far in a Graph Neural Network model."
      ],
      "metadata": {
        "id": "oub6anZdnXjJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Network for graph-level regression"
      ],
      "metadata": {
        "id": "xPd6vIxLT6Cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Hyperparameters GIN \n",
        "\n",
        "BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "NUM_EPOCHS =   30#@param {type:\"integer\"}\n",
        "HIDDEN_DIM =   64#@param {type:\"integer\"}\n",
        "LR         = 0.001 #@param {type:\"number\"}\n",
        "\n",
        "#you can add more here if you need"
      ],
      "metadata": {
        "id": "x0qJSFf13SkK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will design a  Graph Neural Network model, similar to the one used on Cora, with the following modifications:\n",
        "* graph-level prediction instead of node-level prediction\n",
        "* regression instead of classification\n",
        "* to obtain *provable more powerful architecture* $^\\dagger$, we will go beyond GCN Layer and implement a [**GIN Layer**](https://arxiv.org/abs/1810.00826) instead.\n",
        "\n",
        "$^\\dagger$*we will rigurously define what it means in the last section of the Practical*."
      ],
      "metadata": {
        "id": "AMM6-nlDpoOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One simple instantiation of GIN Layer processes the graph according to the following message passing equation, where $\\epsilon_k$ is a learnable scalar\n",
        "\n",
        "\\begin{equation}\n",
        "X^{k+1}= \\text{MLP}_k\\big(AX^k + (1+\\epsilon_k)X^k\\big)\n",
        "\\end{equation}\n",
        "\n",
        "### 💻 **Task 2.3:** Most of the code is provided to you, but you have to fill in the missing part that implements the core message passing equation shown above. (1 Mark)"
      ],
      "metadata": {
        "id": "fWJbB5AFqmD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GINLayer(nn.Module):\n",
        "    \"\"\"A single GIN layer, implementing MLP(AX + (1+eps)X)\"\"\"\n",
        "    def __init__(self, in_feats: int, out_feats: int, hidden_dim: int, eps: float=0.0):\n",
        "        super(GINLayer, self).__init__()\n",
        "        self.in_feats = in_feats\n",
        "        self.out_feats = out_feats\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # epsilon should be a learnable parameter\n",
        "        # self.eps = ... \n",
        "        # =========================================\n",
        "        self.linear1 = nn.Linear(self.in_feats, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, self.out_feats)\n",
        "\n",
        "    def forward(self, x, adj_sparse): \n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # aggregate the neighbours as in GIN: (AX + (1+eps)X)\n",
        "        # x = ...\n",
        "        \n",
        "        # project the features (MLP_k)\n",
        "        # out = \n",
        "        # =========================================\n",
        "        return out"
      ],
      "metadata": {
        "id": "93sKHVmsK_-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the above GIN Layer, let's design a neural network with `num_layers` GINLayers, to solve the graph-regression task\n",
        "\n",
        "### 💻 **Task 2.4:** The code is provided. All you have to do is to fill-in the code that creates graph-representations from node-representations (1 Mark)"
      ],
      "metadata": {
        "id": "J1-DH6bqsuVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.linear import Linear\n",
        "class SimpleGIN(nn.Module):\n",
        "    \"\"\" \n",
        "    A Graph Neural Network containing GIN layers \n",
        "    as in https://arxiv.org/abs/1810.00826 \n",
        "    The readout function used to obtain graph-lvl representations\n",
        "    is just the sum of the nodes in the graph\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Dimensionality of the input feature vectors\n",
        "        output_dim (int): Dimensionality of the output softmax distribution\n",
        "        num_layers (int): Number of layers\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2, eps=0.0, \n",
        "                 molecular=True):\n",
        "        super(SimpleGIN, self).__init__()\n",
        "        self.num_layers = num_layers # please select num_layers>=2\n",
        "        self.molecular = molecular\n",
        "        # nodes in ZINC dataset are characterised by one integer (atom category)\n",
        "        # we will create embeddings from the categorical features using nn.Embedding\n",
        "        if self.molecular:\n",
        "            self.embed_x = Embedding(28, hidden_dim)\n",
        "        else:\n",
        "            self.embed_x = Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # instead of nn.Linear as in SimpleMLP model, \n",
        "        # now we have (num_layers) GINLayer(s), each with different parameters\n",
        "        self.layers = [GINLayer(hidden_dim, hidden_dim, hidden_dim, eps) for _ in range(num_layers-1)]\n",
        "        self.layers += [GINLayer(hidden_dim, output_dim, hidden_dim, eps)]\n",
        "        self.layers = nn.ModuleList(self.layers)\n",
        "    \n",
        "    def forward(self, graph):\n",
        "        adj_sparse = graph.get_adjacency_matrix()\n",
        "        if self.molecular:\n",
        "            x = self.embed_x(graph.x.long()).squeeze(1)\n",
        "        else:\n",
        "            x = self.embed_x(graph.x)\n",
        "\n",
        "        for i in range(self.num_layers-1):\n",
        "          x = self.layers[i](x, adj_sparse)\n",
        "          x = F.relu(x)\n",
        "        x = self.layers[-1](x, adj_sparse)\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # graph-level representations are obtain by pooling info from the nodes using sum\n",
        "        # y_hat = ...\n",
        "        # =========================================\n",
        "\n",
        "        y_hat = y_hat.squeeze(-1)\n",
        "        #return also the final node embeddings (for visualisations)\n",
        "        return y_hat, x"
      ],
      "metadata": {
        "id": "XxxzXYeZHQah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since now we have a proper graph network to play with, let's check if our mini-batch implementation is correct. For this, we provide an unit test checking that runing the code on individual graphs or directly on an entire batch provides the same results: "
      ],
      "metadata": {
        "id": "bMWxqmXduFLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Unit test for mini-batch implementation\n",
        "def unit_test_mini_batch(batch):\n",
        "  model = SimpleGIN(input_dim=batch[0].x.size()[-1], output_dim=1, hidden_dim=HIDDEN_DIM, num_layers=4)\n",
        "\n",
        "  graph_batch = create_mini_batch(batch)\n",
        "  out_batch, _ = model(graph_batch)\n",
        "\n",
        "  for i in range(BATCH_SIZE):\n",
        "    batch_i = create_mini_batch([batch[i]])\n",
        "    out_i, node_emb_i = model(batch_i)\n",
        "    assert(np.abs(out_i.detach().numpy() - out_batch[i].detach().numpy()).mean() <1e-5 )\n",
        "  print(\"Congrats 😊 !! Everything seems all right!\")"
      ],
      "metadata": {
        "id": "ZsWpBF-U7UPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run unit test for mini-batch implementation\n",
        "batch = train_zinc_dataset[:BATCH_SIZE]\n",
        "unit_test_mini_batch(batch)"
      ],
      "metadata": {
        "id": "5lwYEswr8ysD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model, optimiser, epoch, loss_fct, metric_fct, print_every):\n",
        "    \"\"\" Train model for one epoch \n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    num_iter = int(len(dataset)/BATCH_SIZE)\n",
        "    for i in range(num_iter):\n",
        "        batch_list = dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        batch = create_mini_batch(batch_list)\n",
        "        optimiser.zero_grad()\n",
        "        y_hat, _ = model(batch)\n",
        "        loss = loss_fct(y_hat, batch.y)\n",
        "        metric = metric_fct(y_hat, batch.y)\n",
        "        loss.backward()\n",
        "        optimiser.step() \n",
        "        if (i+1) % print_every == 0:\n",
        "          print(f\"Epoch {epoch} Iter {i}/{num_iter}\",\n",
        "                    f\"Loss train {loss.data}; Metric train {metric.data}\")\n",
        "    return loss, metric\n",
        "\n",
        "def evaluate(dataset, model, loss_fct, metrics_fct):\n",
        "    \"\"\" Evaluate model on dataset\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    # be careful in practice, as doing this way we will lose some \n",
        "    # examples from the validation split, when len(dataset)%BATCH_SIZE != 0\n",
        "    # think about how can you fix this!\n",
        "    num_iter = int(len(dataset)/BATCH_SIZE)\n",
        "    metrics_eval = 0\n",
        "    loss_eval = 0\n",
        "    for i in range(num_iter):\n",
        "        batch_list = dataset[i*BATCH_SIZE:(i+1)*BATCH_SIZE]\n",
        "        batch = create_mini_batch(batch_list)\n",
        "        y_hat, _ = model(batch)\n",
        "        metrics = metrics_fct(y_hat, batch.y)\n",
        "        loss = loss_fct(y_hat, batch.y)\n",
        "\n",
        "        metrics_eval += metrics.data\n",
        "        loss_eval += loss.data\n",
        "    metrics_eval /= num_iter\n",
        "    loss_eval /= num_iter\n",
        "    return loss_eval, metrics_eval"
      ],
      "metadata": {
        "id": "eoA03MZK39ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_eval(model, train_dataset, val_dataset, test_dataset, \n",
        "               loss_fct, metric_fct, print_every=1):\n",
        "    \"\"\" Train the model for NUM_EPOCHS epochs\n",
        "    \"\"\"\n",
        "    #Instantiatie our optimiser\n",
        "    optimiser = optim.Adam(model.parameters(), lr=LR)\n",
        "    training_stats = None\n",
        "\n",
        "    #initial evaluation (before training)\n",
        "    val_loss, val_metric = evaluate(val_dataset, model, loss_fct, metric_fct)\n",
        "    train_loss, train_metric = evaluate(train_dataset[:BATCH_SIZE], model, \n",
        "                                        loss_fct, metric_fct)\n",
        "    epoch_stats = {'train_loss': train_loss, 'val_loss': val_loss, \n",
        "                      'train_metric': train_metric, 'val_metric': val_metric, \n",
        "                      'epoch':0}\n",
        "    training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        if isinstance(train_dataset, list):\n",
        "            random.shuffle(train_dataset)\n",
        "        else:\n",
        "            train_dataset.shuffle()\n",
        "        train_loss, train_metric = train(train_dataset, model, optimiser, epoch, \n",
        "                                        loss_fct, metric_fct, print_every)\n",
        "        val_loss, val_metric = evaluate(val_dataset, model, loss_fct, metric_fct)\n",
        "        print(f\"[Epoch {epoch+1}]\",\n",
        "                    f\"train loss: {train_loss:.3f} val loss: {val_loss:.3f}\",\n",
        "                    f\"train metric: {train_metric:.3f} val metric: {val_metric:.3f}\"\n",
        "              )\n",
        "        # store the loss and the computed metric for the final plot\n",
        "        epoch_stats = {'train_loss': train_loss, 'val_loss': val_loss, \n",
        "                      'train_metric': train_metric, 'val_metric': val_metric, \n",
        "                      'epoch':epoch+1}\n",
        "        training_stats = update_stats(training_stats, epoch_stats)\n",
        "\n",
        "    test_loss, test_metric = evaluate(test_dataset, model,  loss_fct, metric_fct)\n",
        "    print(f\"Test metric: {test_metric:.3f}\")\n",
        "    return training_stats"
      ],
      "metadata": {
        "id": "tAj_mIDnnace"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to train our model and enjoy the results. "
      ],
      "metadata": {
        "id": "Gh5irkVH8lOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate our GIN model\n",
        "model_simple_gin = SimpleGIN(input_dim=batch_zinc.x.size()[-1], output_dim=1, hidden_dim=HIDDEN_DIM, num_layers=4, eps=0.1)\n",
        "out, _ = model_simple_gin(batch_zinc)\n",
        "print(out.detach().numpy())"
      ],
      "metadata": {
        "id": "eWBtK14LN0TY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train GIN model:\n",
        "train_stats_simple_gin_zinc = train_eval(model_simple_gin, train_zinc_dataset, val_zinc_dataset, \n",
        "                                  test_zinc_dataset, loss_fct=F.mse_loss, \n",
        "                                  metric_fct=F.mse_loss, print_every=150)\n",
        "plot_stats(train_stats_simple_gin_zinc, name='Simple_GIN_ZINC', figsize=(5, 10))"
      ],
      "metadata": {
        "id": "5DueMpa54X27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The full GIN architecture as introduced in the original [paper](https://arxiv.org/pdf/1810.00826.pdf), does not use only the final output for predictions. Instead, it creates a graph representation from the representation of all the intermediate layers:\n",
        "\n",
        "\\begin{equation}\n",
        "h_G = CONCAT\\big(\\oplus_{v \\in G}\\{h_v^{(k)}\\}| k=0,1..(K-1) \\big)\n",
        "\\end{equation}\n",
        "\n",
        "where $\\oplus_{v \\in G}\\{h_v^{(k)}\\}$ represents the graph-level representations at layer $k$, obtained by summing the representations from all the nodes $v \\in G$\n",
        "\n",
        "\\\\\n",
        "\n",
        "### 💻 **Task 2.5:** Implement the entire architecture as described above. (1 Mark)"
      ],
      "metadata": {
        "id": "J0dNtI6dWAGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GIN(nn.Module):\n",
        "    \"\"\" \n",
        "    A Graph Neural Network containing GIN layers \n",
        "    as in https://arxiv.org/abs/1810.00826 \n",
        "    The readout function used to obtain graph-lvl representations\n",
        "    aggregate pred from multiple layers (as in JK-Net)\n",
        "\n",
        "    Args:\n",
        "    input_dim (int): Dimensionality of the input feature vectors\n",
        "    output_dim (int): Dimensionality of the output softmax distribution\n",
        "    num_layers (int): Number of layers\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim, num_layers=2, eps=0.0, \\\n",
        "                 molecular=True):\n",
        "        super(GIN, self).__init__()\n",
        "        self.num_layers = num_layers \n",
        "        self.molecular = molecular\n",
        "        # nodes in ZINC dataset are characterised by one integer (atom category)\n",
        "        # we will create embeddings from the categorical features using nn.Embedding\n",
        "        if self.molecular:\n",
        "            self.embed_x = Embedding(28, hidden_dim)\n",
        "        else:\n",
        "            self.embed_x = Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # ============ YOUR CODE HERE =============\n",
        "        # should be the same as before (an nn.ModuleList of GINLayers)\n",
        "        # self.layers = ...\n",
        "\n",
        "        # layer to compute prediction from the concatenated intermediate representations\n",
        "        # self.pred_layers = ...\n",
        "        # =========================================\n",
        "\n",
        "    def forward(self, graph):\n",
        "        adj_sparse = graph.get_adjacency_matrix()\n",
        "        if self.molecular:\n",
        "            x = self.embed_x(graph.x.long()).squeeze(1)\n",
        "        else:\n",
        "            x = self.embed_x(graph.x)\n",
        "\n",
        "        # ============ YOUR CODE HERE ============= \n",
        "        # perform the forward pass with the new readout function  \n",
        "        for i in range(self.num_layers-1):\n",
        "            # x = ...\n",
        "            pass\n",
        "        # y_hat = ...\n",
        "        pass\n",
        "        # =========================================\n",
        "        # return also the final node embeddings (for visualisations)\n",
        "        return y_hat, x"
      ],
      "metadata": {
        "id": "rIuL92VZgSot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gin = GIN(input_dim=batch_zinc.x.size()[-1], output_dim=1, hidden_dim=HIDDEN_DIM, num_layers=4, eps=0.1)\n",
        "out, _ = model_gin(batch_zinc)\n",
        "print(out.detach().numpy())\n",
        "\n",
        "#Train GIN model:\n",
        "train_stats_gin_zinc = train_eval(model_gin, train_zinc_dataset, val_zinc_dataset, \n",
        "                                  test_zinc_dataset, loss_fct=F.mse_loss, \n",
        "                                  metric_fct=F.mse_loss, print_every=150)\n",
        "plot_stats(train_stats_gin_zinc, name='GIN_ZINC', figsize=(5, 10))"
      ],
      "metadata": {
        "id": "ObvHuN2KWDtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Expressive Power of Graph Neural Networks\n",
        "\n"
      ],
      "metadata": {
        "id": "ieg7RjeGUEm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should be already confident that Graph Neural Networks represents powerful tools to process graph-data. However, there are some theoretically proven limitations that you should be aware of. From now on, your goal in this practical will be to **understand and overcome these limitations**.\n",
        "\n",
        "In the following, we will look at 2 hard to distinguish  graphs and try to understand what are the problems that GNNs are not able to solve and why this happends."
      ],
      "metadata": {
        "id": "OxFXFxSmusi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Hard to distinguish graphs\n",
        "def gen_hard_graphs_WL():\n",
        "  \n",
        "  x1 = torch.ones((10,1))\n",
        "  edge_index1 = torch.tensor([[1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10],\n",
        "                 [2, 5, 1, 3, 2, 4, 6, 3, 5, 1, 4, 3, 7, 10, 6, 8, 7, 9, 8, 10, 6, 9]])-1\n",
        "  y1 = torch.tensor([1])\n",
        "\n",
        "  x2 = torch.ones((10,1))\n",
        "  edge_index2 = torch.tensor([[1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10],\n",
        "                 [2, 6, 1, 3, 7, 2, 4, 10, 3, 5, 4, 6, 1, 5, 2, 8, 7, 9, 8, 10, 3, 9]])-1\n",
        "  y2 =  torch.tensor([2])  \n",
        "\n",
        "  graph1 = Graph(x=x1, edge_index=edge_index1, y=y1)\n",
        "  graph2 = Graph(x=x2, edge_index=edge_index2, y=y2)\n",
        "  return [graph1, graph2]"
      ],
      "metadata": {
        "id": "GCue41Zm2yas",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_graphs = gen_hard_graphs_WL()\n",
        "gallery(hard_graphs, labels=[\"A\",\"B\"], max_fig_size=(10,5))"
      ],
      "metadata": {
        "id": "o6puEEq09B0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to encode these graphs using our GIN Neural Network."
      ],
      "metadata": {
        "id": "8ez1d5Qa1tb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hard_batch = create_mini_batch(hard_graphs)\n",
        "out, node_emb = model_simple_gin(hard_batch)\n",
        "\n",
        "#split node_emb from batch into separate graphs\n",
        "node_emb = node_emb.detach().numpy()\n",
        "node_emb_split=[node_emb[:hard_graphs[0].num_nodes], node_emb[hard_graphs[0].num_nodes:]]\n",
        "\n",
        "#encode node representation into an int in [0,1] denoting the color\n",
        "node_emb_split = hash_node_embedings(node_emb_split)\n",
        "\n",
        "\n",
        "gallery(hard_graphs, node_emb=node_emb_split, max_fig_size=(10,5))\n"
      ],
      "metadata": {
        "id": "SILuJng_CkNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the visualisation from above, the colors indicate the nodes embedings, as predicted by the model. Remember from the course that, to obtain a graph-level representation, we pool the nodes embedings using a *permutation invariant* function. This means that the multisets of colors determine the graph embeding. More exactly, if two graphs are encoded using the same multisets of colors, the final graph-representation will be the same.\n",
        "This means that from the graph-level perspective the 2 graphs shown above are the same. However, for a human, it is obvious that this is not true.\n",
        "\n",
        "**Why this is happening ❓**\n",
        "\n",
        "Let's look at how the node embedings are computed by a 5-layer GNN."
      ],
      "metadata": {
        "id": "xIgLJztn150N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<!-- <center> -->\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Jt6zJVApmgS9VFbcKpzxOoBtrxos55iu\" width=\"1000\">\n",
        "<!-- </center> -->"
      ],
      "metadata": {
        "id": "g7mjYC-J6F_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we are looking into how the computational network looks like for the two graphs in 5 steps, we observe that they essentially looks very similar. The **important** difference that we are able to spot, while the GNNs are not, is that, after 5 layers of propagation, in one graph (left) we reach the same note from where we've started, while in the other graph (right) we reach a different one. Since from the structure persective the 2 nodes are the same, the GNN will encode them the same without realising the difference between them. \n",
        "\n",
        "In the next section we will try to find how can we alleviate this and what could be the practical implications this problem raise."
      ],
      "metadata": {
        "id": "hsLMZcjKG_51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improving the expressive power"
      ],
      "metadata": {
        "id": "t1RzUDM4URs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have seen in the example above, GIN (and MPNNs in general) cannot distinguih any pair of non-isomorphic graphs. Based on this, we can devise a hierarchy of GNN models based on what pairs of graphs they can or cannot distinguish. \n",
        "\n",
        "**Definition.** *We say that a GNN model B is strictly more powerful than another model A if B can distinguish all the pairs of attributed graphs that A can distinguish and there exists a pair of attributed graphs that B can distiguish but A cannot.*\n",
        "\n",
        "In this section, we are going to build a GNN model that is more powerful than GIN and design a synthetic task on which this can be evaluated emprically. Then, you will also be asked to prove mathematically that your model is indeed more powerful."
      ],
      "metadata": {
        "id": "UgQBMSu0zwzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 3.1:** Construct a graph classification or regression task where a model with superior expressive power should do better than GIN. Split your dataset in a training, validation and testing subsets. (1 Mark)\n",
        "\n",
        "Hint: Try to find more examples of pairs of graphs that GIN cannot distiguish and generalise them into a dataset. "
      ],
      "metadata": {
        "id": "al8DGpgM0Pc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ YOUR CODE HERE =============\n",
        "# Construct dataset.\n",
        "# ========================================="
      ],
      "metadata": {
        "id": "BP9l77MDzAIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 3.2:** Think of a feature augmentation procedure that can increase the expressive power of GIN. Is GIN + Feature Augmentation better than GIN on the synthetic task? Explain your results. (1 Mark)\n",
        "\n",
        "How can you augment the initial graph features with additional information about the graph that could lead to higher discriminativity when applying a GIN model on top? "
      ],
      "metadata": {
        "id": "ngDiEm6p1EqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ YOUR CODE HERE =============\n",
        "# Implement GIN with Feature Augmentation\n",
        "# ========================================="
      ],
      "metadata": {
        "id": "O5ePwBht1Gwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ YOUR CODE HERE =============\n",
        "# Evaluate your model on this new dataset against GIN.\n",
        "# ========================================="
      ],
      "metadata": {
        "id": "kjV5RX1q11VX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💻**Task 3.3:** Prove mathematically that GIN + Feature Augmentation is indeed strictly more powerful than vanilla GIN. (1 Mark)\n",
        "\n",
        "Following our definition of more powerful, we will adopt a two steps approach. Firstly, prove that your model is at least as powerful as GIN (i.e. it can also distiguish all pairs that GIN can distinguish) and, secondly, that your model can also distinguish additional pairs compared to GIN. \n",
        "\n",
        "Let us write the local aggregation performed by GIN more abstractly as $x_v^{k+1} = f_{\\text{GIN}}(x_v^k, \\{\\{ x_u^k \\mid u \\in \\mathcal{N}(v)\\}\\})$, where $\\{\\{ ... \\}\\}$ denotes a multiset and $x_v^k$ the feature of node $v$ at layer $k$. Notice that GIN is maximally expressive when $f_{\\text{GIN}}$ is injective because it allows it to map different neighbourhoods to different embeddings, which leads to higher discriminative power. We will use as a fact (i.e. no proof) that there exist a set of parameters that make $f_{\\text{GIN}}$ injective. \n",
        "\n",
        "Thus, for the first part of the proof, prove the following steps:\n",
        "\n",
        "**Step 1:** Denote by $x_v^k$ the features of node $v$ at layer $k$ of a GIN model with injective layers. Similarly, denote by $y_v^k$ the features of a second GIN model with injective layers and augmented features at $k=0$. Prove by induction that for any two nodes $v, u$ from two arbitrary graphs, if $y_v^k = y_u^k$, then $x_v^k = x_u^k$. \n",
        "\n",
        "**Step 2:** Prove that for any two graphs $\\mathcal{G_1}, \\mathcal{G_2}$, if $\\{\\{x_v^{k} \\mid  v \\in V_{\\mathcal{G_1}} \\}\\} \\neq \\{\\{x_u^{k} \\mid  u \\in V_{\\mathcal{G_2}}\\}\\}$, then $\\{\\{y_v^{k} \\mid  v \\in V_{\\mathcal{G_1}} \\}\\} \\neq \\{\\{y_u^{k} \\mid  u \\in V_{\\mathcal{G_2}}\\}\\}$. "
      ],
      "metadata": {
        "id": "Pb9Iqrmb1xc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Proof.*** Add you proof here"
      ],
      "metadata": {
        "id": "d2ocV-ZR2pN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let us test the model you proposed above in a real-world setting. \n",
        "\n",
        "### 💻**Task 3.4:** Evaluate GIN + feature augmentation on ZINC and compare your results to the vanilla GIN. Is your model doing better? In either case, explain the results you obtain. (0.5 Marks)"
      ],
      "metadata": {
        "id": "LeSamI5O3P_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ YOUR CODE HERE =============\n",
        "# Evaluate your model on ZINC\n",
        "# ========================================="
      ],
      "metadata": {
        "id": "y3k8on9j2LXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 💻**Task 3.5:** Beyond message passing (2.5 Marks)\n",
        "\n",
        "We will end this practical with an open-ended task for extra points. \n",
        "\n",
        "So far, we have only looked at increasing the expressive power by adding additional features to the initial features of a graph. An alternative is to modify the computational graph of the model. In other words, we could perform computations that go beyond the traditional message passing approach that you have seen in the lectures and in this practical, which could ultimately lead to improved discriminative power. \n",
        "\n",
        "1.   Design a model that is strictly more expressive than GIN by going beyond the regular message passing between nodes.  \n",
        "2.   Prove that your model is indeed strictly more powerful than GIN.\n",
        "3.   Prove and write a test to check that the layers of your model are permutation equivariant. \n",
        "4.   Evaluate your model on ZINC. How does it compare to the GIN and GIN + Augmented Features models from above? \n",
        "5.   Discuss the computational complexity of your solution? How does it compare with the complexity of message passing approaches? Can the complexity of your solution be improved? \n",
        "\n"
      ],
      "metadata": {
        "id": "G1-Oso8S3FF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dRUnoG3dCOFK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}